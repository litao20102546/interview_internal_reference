# OpenStack项目

## array-lbaasv2-agent 如何加载和继承

这个就涉及到OpenStack neutron plugin 加载机制了， 通过读取配置文件中的core_plugin 和service_plugin明确要加载的模块，然后会调用到neutron load_drivers函数，最后调用到oslo_utils importutils类，import_object函数，最终会解析object 为module_str, class_str,然后利用`__import__(module_str)`加载模块，然后利用getattr(sys.modules[module_str], class_str)加载类

# k8s项目

## k8s-array-controller

### CRD类型定义

增加开关，针对特定有need-auto-LBRoute label的namespace进行自动化服务发现和发布（采用serverless事件触发机制），
LBRoute 是名称空间级别的可用资源

```yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: LBRoute.LBRouteController.k8s.io
spec:
  validation：
    openAPIV3Schema
      properties:
        spec:
          properties:
            vsName:
            vsIP
            protocol:
            policy:
  group: LBRouteController.k8s.io
  version: v1alpha1
  names:
    kind: LBRoute
    plural: foos
  scope: Namespaced
  addtionalPrinterColumns:
  -name VS
  -name Group
  -name RS
  -name policy
```

### APV设备怎么加入集群

* 将负载均衡设备作为边缘节点，平滑的部署到集群中以实现Flannel和calico等多种网络的支持。
* 边缘节点不进行调度任务, no-schedule
* 在APV实现calico client quggua（强大于bird）通过设置相同的asn, neighbor router

## serverless 监控，告警，自修复

* cronjob 每10分钟触发一次，slink是Knative的scanLB service
* scanLB service负责扫描硬负载设备，并将扫描结果传到移动table_store, 为了保存事件历史消息，扫描的信息一方面是TLS链接相关，一方面是SLB相关，还有基础信息（HA状态，interface状态，CPU，内存信息）
* 基于table_store事件源中sanLB tableName由brocker响应
* trigger订阅scanLB事件，然后触发TLS和SLB两个订阅（subscribe），均有Knative service实现订阅逻辑。分别发送给负责TLS和SLB的team。

## 社区贡献代码做了什么

* https://github.com/kubernetes/kubernetes/commit/db537e5954c6517f168a59c3f97b1bd3c80f80df
* https://cloud.tencent.com/developer/article/1650756
* Add Annotations from the deviceplugin to the runtime
* https://www.kubernetes.org.cn/4391.html
* [RenaudWasTaken](https://github.com/kubernetes/kubernetes/commits?author=RenaudWasTaken) 



## 遇到过什么问题

https://www.cnblogs.com/gaorong/p/10925480.html

总结：

* **问题**：收到大量node notready 报警

* 检查问题：发现apiserver正常工作，kubelet 与apiserver连接心跳timeout， 抓包分析，发现kubelet不断地给apiservre发送包却没有收到对端的`ACK`， 重启kubelet就正常了。

* **进一步根据日志分析**问题。发现LB负载apiserver异常日志时间和kubelet报错时间相同。是因为LB新增一台硬件，然后会分摊一部分流量，分摊的流量找不到connection记录就认为是非法的会drop掉。这是LB的Bug。

* 但是为了提高容错性需要改进kubelet.想的是当kubelet连接apiserver超时之后， 应该reset 掉连接， 进行重试。

* 通过使用`iptables`规则`drop`掉kubelet发出的流量来模拟网络异常可以复现问题

* 更深入的查找原因发现HTTP1.1没有问题，http2有问题.

  * 在http1.1中，默认采用`keep-alive`复用网络连接，发起新的请求时， 如果当前有闲置的连接就会复用该连接， 如果没有则新建一个连接。当kubelet连接异常时，老的连接被占用，一直hang在等待对端响应，kubelet在下一次心跳周期，因为没有可用连接就会新建一个，只要新连接正常通信，心跳包就可以正常发送

  * 在http2中，为了提高网络性能，一个主机只建立一个连接，所有的请求都通过该连接进行，默认情况下，即使网络异常，他还是重用这个连接，直到操作系统将连接关闭，而操作系统关闭僵尸连接的时间默认是十几分钟，

* **最优办法**：更为好的方法不是弃用http2，而是修复HTTP2带来的这个问题，发现h2主动探测连接故障是通过发送`Ping frame`来实现，可是该frame默认不会发送， 需要显式设置才会发送。（gRPC 为了快速识别故障连接并恢复采用了`Ping frame`）.但是目前kubernetes所建立的连接中并没有实现`Ping frame`， 导致了无法及时发现连接异常并自愈。

* 社区那个issue已经开了很长时间好像并没有解决的痕迹，还得自己想办法。我们知道一个http.Client本身其实只做了一些http协议的处理，底层的通信是交给`Transport`来实现, `Transport`决定如何根据一个`request`返回对应的`response`。在kubernetes client-go中关于`Transport`h2的设置只有这一个函数

  ```go
  // SetTransportDefaults applies the defaults from http.DefaultTransport
  // for the Proxy, Dial, and TLSHandshakeTimeout fields if unset
  func SetTransportDefaults(t *http.Transport) *http.Transport {
  	t = SetOldTransportDefaults(t)
  	// Allow clients to disable http2 if needed.
  	if s := os.Getenv("DISABLE_HTTP2"); len(s) > 0 {
  		klog.Infof("HTTP2 has been explicitly disabled")
  	} else {
  		if err := http2.ConfigureTransport(t); err != nil {
  			klog.Warningf("Transport failed http2 configuration: %v", err)
  		}
  	}
  	return t
  }
  ```

  只是调用了`http2.ConfigureTransport`来设置transport支持h2。这一句代码似乎太过简单，并没有任何`Ping frame`相关的处理逻辑。查了下golang标准库中`Transport`与`Ping frame`相关的方法，令遗憾的是，当前golang 对于一个`tcp`连接的抽象`ClientConn`已经支持发送`Ping frame`，但是连接是交由连接池`clientConnPool`管理的， 该结构是个内部的私有结构体，我们没法直接操作，封装连接池的`Transport`也没有暴露任何的接口来实现**设置连接池中的所有连接定期发送`Ping frame`**。如果我们想实现这个功能就必须自定义一个`Transport`并实现一个连接池，要实现一个稳定可靠的`Transport`似乎并不容易。只能求助golang社区看有没有解决方案， 提交了一个issue后：[x/net/http2: make Transport occasionally send PING frames to server #31643](https://github.com/golang/go/issues/31643), 很快就有人回复并提交了PR，查看了一下，实现还是比较简单的，于是基于这个PR实现了`clinet-go`的`Ping frame`的探测。

修复https://github.com/golang/net/commit/0ba52f642ac2f9371a88bfdde41f4b4e195a37c0

src/github.com/arraynetworks/k8s-array-controller/vendor/k8s.io/client-go/transport/cache.go utilnet.SetTransportDefaults

```go
	func (cc *ClientConn) healthCheck() {
	pingTimeout := cc.t.pingTimeout()
	// We don't need to periodically ping in the health check, because the readLoop of ClientConn will
	// trigger the healthCheck again if there is no frame received.
	ctx, cancel := context.WithTimeout(context.Background(), pingTimeout)
	defer cancel()
	err := cc.Ping(ctx)
	if err != nil {
		cc.closeForLostPing()
		cc.t.connPool().MarkDead(cc)
		return
	}
}

gotSettings := false
	readIdleTimeout := cc.t.ReadIdleTimeout
	var t *time.Timer
	if readIdleTimeout != 0 {
		t = time.AfterFunc(readIdleTimeout, cc.healthCheck)
		defer t.Stop()
	}
	for {
		f, err := cc.fr.ReadFrame()
		if t != nil {
			t.Reset(readIdleTimeout)
		}
```



## 大规模场景下 kubernetes 集群的性能优化

https://www.jianshu.com/p/4525aff0c4ac

### 基于MutatingAdmissionWebhook实现资源超卖

https://blog.csdn.net/qq_17305249/article/details/105024493

* 当requests字段设置太大的时候，pod实际使用的资源却很小，导致计算节点的Allocatable值很快就被消耗完，节点的资源利用率会变得很低。

* 上图通过将allocatable值扩大（fake allcatable），让更多的pod调度到了该节点，节点的资源利用率 current / allocatable 就变大了

* 实现资源超卖的关键在于动态修改节点Node对象的allocatable字段值，而我们看到allocatable字段属于Status字段，显然不能直接通过kubectl edit命令来直接修改。因为Status字段和Spec字段不同，Spec是用户设置的期望数据，而Status是实际数据（Node节点通过不断向apiServer发送心跳来更新自己的实时状态，最终存在etcd中）。那么我们要怎么去修改Stauts字段呢？

* 开始想法：可以通过patch或者put方法来调用k8s的RESTful API，实现Stauts字段的修改。（这里是通过ApiServer去修改etcd中保存的Status字段的值）。但是，Node资源对象比较特殊，计算节点会不断给ApiServer发送心跳（默认每隔10s发一次），将带有Status字段的真实信息发送给ApiServer，并更新到etcd中。也就是无论你怎么通过patch/put方法去修改Node的Status字段，计算节点都会定时通过发送心跳将真实的Status数据覆盖你修改的数据，也就是说我们无法通过直接调用RESTful API修改Node对象中的Status数据。

* k8s在ApiServer中就提供了Admission Controller（准入控制器）的机制，其中包括了MutatingAdmissionWebhook，通过这个webhook，所有和集群中所有和ApiSever交互的请求都被发送到一个指定的接口中，我们只要提供一个这样的接口，就可以获取到Node往ApiServer发送心跳的Staus数据了。然后将这个数据进行我们的自定义修改，再往后传给etcd，就能让etcd以为我们修改过的Status数据就是节点的真实Status，最终实现资源的超卖。

  进一步了解MutatingWebhookConfiguration

  MutatingWebhookConfiguration监听了集群中nodes资源的status数据向apiServer提交的更新操作（就是我们前面提到的心跳信息），并且将所有的心跳信息发给了名为webhook-oversale-service的Service下的/mutate接口处理，这个接口就是我们自定义的webhook服务提供的。
  
  ```yaml
  apiVersion: admissionregistration.k8s.io/v1beta1
  kind: MutatingWebhookConfiguration
  metadata:
    creationTimestamp: null
    name: mutating-webhook-oversale
  webhooks:
  - clientConfig:
      caBundle: ...
      service:
        name: webhook-oversale-service
        namespace: oversale
        path: /mutate
    failurePolicy: Ignore
    name: oversale
    rules:
    - apiGroups:
      - *
      apiVersions:
      - v1
      operations:
      - UPDATE
      resources:
      - nodes/status
  ```
  
  

### etcd

- 1、etcd 采用本地 ssd 盘作为后端存储存储
- 2、etcd 独立部署在非 k8s node 上
- 3、etcd 快照(snap)与预写式日志(wal)分盘存储

etcd 详细的优化操作可以参考上篇文章：[etcd 性能测试与调优](http://blog.tianfeiyu.com/2019/10/08/etcd_improvements/)。

* 对于不同 object 进行分库存储，首先应该将数据与状态分离，即将 events 放在单独的 etcd 实例中，在 apiserver 的配置中加上`--etcd-servers-overrides=/events#https://xxx:3379;https://xxx:3379;https://xxx:3379;https://xxxx:3379;https://xxx:3379`，后期可以将 pod、node  等 object 也分离在单独的 etcd 实例中。

### apiserver 的优化

#### 1、参数调整

- `--max-mutating-requests-inflight` ：在给定时间内的最大 mutating 请求数，调整 apiserver 的流控 qos，可以调整至 3000，默认为 200
- `--max-requests-inflight`：在给定时间内的最大 non-mutating 请求数，默认 400，可以调整至 1000
- `--watch-cache-sizes`：调大 resources 的 watch size，默认为 100，当集群中 node 以及 pod 数量非常多时可以稍微调大，比如： `--watch-cache-sizes=node#1000,pod#5000`

#### 2、etcd 多实例支持

对于不同 object 进行分库存储，首先应该将数据与状态分离，即将 events 放在单独的 etcd 实例中，在 apiserver 的配置中加上`--etcd-servers-overrides=/events#https://xxx:3379;https://xxx:3379;https://xxx:3379;https://xxxx:3379;https://xxx:3379`，后期可以将 pod、node  等 object 也分离在单独的 etcd 实例中。

#### 3、apiserver 的

#### 4、使用 pprof 进行性能分析

pprof 是 golang 的一大杀器，要想进行源码级别的性能分析，必须使用 pprof。

### kube-controller-manager 的优化

#### 1、参数优化

- 调大 --kube-api-qps 值：可以调整至 100，默认值为 20
- 调大 --kube-api-burst 值：可以调整至 100，默认值为 30
- 禁用不需要的 controller：kubernetes v1.14 中已有 35 个 controller，默认启动为`--controllers`，即启动所有 controller，可以禁用不需要的 controller
- 调整 controller 同步资源的周期：避免过多的资源同步导致集群资源的消耗，所有带有 `--concurrent` 前缀的参数

### kube-scheduler 优化

在 k8s 核心组件中，调度器的功能做的比较通用，大部分公司都不会局限于当前调度器的功能而进行一系列的改造，例如美团就对 kube-scheduler 进行过一些优化，并将[**预选失败中断机制**](https://tech.meituan.com/2019/08/22/kubernetes-cluster-management-practice.html)（详见[PR](https://tech.meituan.com/2019/08/22/kubernetes-cluster-management-practice.html)）和[**将全局最优解改为局部最优解**](https://tech.meituan.com/2019/08/22/kubernetes-cluster-management-practice.html)（详见[PR1](https://github.com/kubernetes/kubernetes/pull/66733)，[PR2](https://github.com/kubernetes/kubernetes/pull/67555)）等重要 feature 回馈给了社区。

首先还是使用好调度器的基本功能：

- [Pod/Node Affinity & Anti-affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity)
- [Taint & Toleration](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)
- [Priority & Preemption](https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/)
- [Pod Disruption Budget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/)

然后再进行一些必要的优化。

#### 1、参数优化

调大`--kube-api-qps` 值：可以调整至 100，默认值为 50

#### 2、调度器优化

- 扩展调度器功能：目前可以通过 [scheduler_extender](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md) 很方便的扩展调度器，比如对于 [GPU](https://cloud.tencent.com/product/gpu?from=10680) 的调度，可以通过  [scheduler_extender](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md)  + [device-plugins](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/) 来支持。
- [多调度器](https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/)支持：kubernetes 也支持在集群中运行多个调度器调度不同作业，例如可以在 pod 的 `spec.schedulerName` 指定对应的调度器，也可以在 job 的 `.spec.template.spec.schedulerName` 指定调度器。
- 动态调度支持：由于 kubernetes 的默认调度器只在 pod 创建过程中进行一次性调度，后续不会重新去平衡 pod 在集群中的分布，导致实际的资源使用率不均衡，此时集群中会存在部分热点宿主，为了解决默认调度器的功能缺陷，kubernetes 孵化了一个工具 [Descheduler](https://github.com/kubernetes-incubator/descheduler) 来对默认调度器的功能进行一些补充，详细说明可以参考官方文档。

#### 3、其他优化策略

- 根据实际资源使用率进行调度：目前默认的调度仅根据 pod 的 request 值进行调度，对于一些资源使用率非常不均衡的场景可以考虑直接以实际的使用率进行调度。
- 等价类划分（Equivalence classes）:典型的用户扩容请求为一次扩容多个容器，因此我 们通过将 pending 队列中的请求划分等价类的方式，实现批处理，显著的降 低 Predicates/Priorities 的次数，这是阿里在今年的 kubeCon 上提出的一个优化方式。

### kubelet 优化



# K8S知识问答

src/github.com/arraynetworks/k8s-array-controller/vendor/k8s.io/apimachinery/pkg/util/net/http.go SetTransportDefaults

## deployment 启动流程

## client-go源码

## 一个请求到pod的过程

# Knative

使用istio-gateway承接Knative的南北流量

